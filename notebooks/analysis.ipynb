{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os , sys\n",
    "import yaml\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'scripts' directory to the Python path\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "\n",
    "from data_loader import load_data, inspect_data, handle_missing_values, load_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 1048575 rows and 6 columns.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1048575 non-null  int64 \n",
      " 1   headline    1048575 non-null  object\n",
      " 2   url         1048575 non-null  object\n",
      " 3   publisher   1048575 non-null  object\n",
      " 4   date        1048575 non-null  object\n",
      " 5   stock       1048575 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 48.0+ MB\n",
      "None\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n",
      "Missing values per column:\n",
      " Unnamed: 0    0\n",
      "headline      0\n",
      "url           0\n",
      "publisher     0\n",
      "date          0\n",
      "stock         0\n",
      "dtype: int64\n",
      "Dataset after dropping missing values: 1048575 rows.\n",
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_data, inspect_data, handle_missing_values, load_config\n",
    "\n",
    "# Load configuration with the correct path\n",
    "config = load_config(config_file='../config.yaml')\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "data = load_data(config['dataset_path'])\n",
    "\n",
    "# Step 2: Inspect Dataset\n",
    "inspect_data(data)\n",
    "\n",
    "# Step 3: Handle Missing Values\n",
    "data_cleaned = handle_missing_values(data)\n",
    "\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics for text lengths:\n",
      " count    1.048575e+06\n",
      "mean     7.300076e+01\n",
      "std      4.029646e+01\n",
      "min      3.000000e+00\n",
      "25%      4.700000e+01\n",
      "50%      6.400000e+01\n",
      "75%      8.700000e+01\n",
      "max      5.120000e+02\n",
      "Name: text_length, dtype: float64\n",
      "Articles per publisher:\n",
      " publisher\n",
      "Paul Quintaro                 168435\n",
      "Lisa Levin                    139785\n",
      "Benzinga Newsdesk             111281\n",
      "Charles Gross                  72892\n",
      "Monica Gerson                  61374\n",
      "                               ...  \n",
      "Silvio Tavares                     1\n",
      "Matthew Boesler                    1\n",
      "Bull Market Bear                   1\n",
      "vic@forextraininggroup.com         1\n",
      "Ryan Smith                         1\n",
      "Name: count, Length: 984, dtype: int64\n",
      "Publication trends:\n",
      " date\n",
      "2011-04-27 21:01:48-04:00    1\n",
      "2011-04-28 13:49:29-04:00    1\n",
      "2011-04-28 15:00:36-04:00    1\n",
      "2011-04-29 13:47:06-04:00    1\n",
      "2011-04-29 16:11:05-04:00    1\n",
      "                            ..\n",
      "2020-06-11 16:15:38-04:00    1\n",
      "2020-06-11 16:24:41-04:00    1\n",
      "2020-06-11 16:25:21-04:00    1\n",
      "2020-06-11 16:49:41-04:00    1\n",
      "2020-06-11 17:11:20-04:00    1\n",
      "Name: count, Length: 27314, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10624\\3217253071.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data['date'] = pd.to_datetime(data['date'], infer_datetime_format=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_data\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(config['dataset_path'])\n",
    "\n",
    "# Analyze text lengths of the 'headline' column\n",
    "data['text_length'] = data['headline'].apply(len)\n",
    "print(\"Basic statistics for text lengths:\\n\", data['text_length'].describe())\n",
    "\n",
    "# Count articles per publisher\n",
    "publisher_counts = data['publisher'].value_counts()\n",
    "print(\"Articles per publisher:\\n\", publisher_counts)\n",
    "\n",
    "# Analyze publication trends over time\n",
    "data['date'] = pd.to_datetime(data['date'], infer_datetime_format=True, errors='coerce')\n",
    "date_counts = data['date'].value_counts().sort_index()\n",
    "print(\"Publication trends:\\n\", date_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
